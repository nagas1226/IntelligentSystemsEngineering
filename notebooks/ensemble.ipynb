{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24edc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from src.features.preprocess import Preprocessor\n",
    "from src.metrics import rmse\n",
    "from src.config.default_config import get_default_config\n",
    "\n",
    "train_df = pl.read_csv(\"../dataset/projectA_vehicle_train.csv\").drop(\n",
    "    \"posting_date\", \"id\"\n",
    ")\n",
    "val_df = pl.read_csv(\"../dataset/projectA_vehicle_val.csv\").drop(\"posting_date\", \"id\")\n",
    "test_df = pl.read_csv(\"../dataset/projectA_vehicle_test.csv\").drop(\"posting_date\", \"id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c93ec4",
   "metadata": {},
   "source": [
    "# regression model with outlier removed dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(\n",
    "    train_df, val_df, test_df\n",
    ") -> tuple[lgb.Booster, pl.Series, pl.Series, pl.Series]:\n",
    "    # デフォルト設定を取得\n",
    "    config = get_default_config()\n",
    "\n",
    "    # 異常検知用に価格の境界を調整（外れ値を除去しない）_config,\n",
    "    config.price_lower_bound = 1_000\n",
    "    config.price_upper_bound = 40_000\n",
    "    config.remove_outliers_val = True\n",
    "\n",
    "    # Preprocessorを作成\n",
    "    preprocessor = Preprocessor(**config.to_dict())\n",
    "\n",
    "    train_df_preprocessed, val_df_preprocessed, test_df_preprocessed = preprocessor.run(\n",
    "        train_df, val_df, test_df\n",
    "    )\n",
    "\n",
    "    # dataset\n",
    "    train_set = lgb.Dataset(\n",
    "        train_df_preprocessed.drop(\"price\").to_pandas(),\n",
    "        train_df_preprocessed[\"price\"].to_pandas(),\n",
    "    )\n",
    "    val_set = lgb.Dataset(\n",
    "        val_df_preprocessed.drop(\"price\").to_pandas(),\n",
    "        val_df_preprocessed[\"price\"].to_pandas(),\n",
    "        reference=train_set,\n",
    "    )\n",
    "\n",
    "    # モデルの学習\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    # モデルの学習\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_set],\n",
    "    )\n",
    "\n",
    "    # 予測\n",
    "    y_pred_train = model.predict(train_df_preprocessed.drop(\"price\").to_pandas())\n",
    "    y_pred_val = model.predict(val_df_preprocessed.drop(\"price\").to_pandas())\n",
    "    y_pred_test = model.predict(test_df_preprocessed.drop(\"price\").to_pandas())\n",
    "\n",
    "    # 評価\n",
    "    train_rmse = rmse(train_df_preprocessed[\"price\"].to_numpy(), y_pred_train)\n",
    "    val_rmse = rmse(val_df_preprocessed[\"price\"].to_numpy(), y_pred_val)\n",
    "    test_rmse = rmse(test_df_preprocessed[\"price\"].to_numpy(), y_pred_test)\n",
    "\n",
    "    print(f\"Train RMSE: {train_rmse:,.0f}\")\n",
    "    print(f\"Validation RMSE: {val_rmse:,.0f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:,.0f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4ef9938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1,313\n",
      "Validation RMSE: 4,358\n",
      "Test RMSE: 7,508\n"
     ]
    }
   ],
   "source": [
    "regression_model = train_regression_model(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09540d10",
   "metadata": {},
   "source": [
    "# anomaly detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d3ac52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price bounds: 0 - inf\n",
      "Remove outliers: False\n",
      "Threshold for anomaly detection: 0.2\n",
      "=============Precision=============\n",
      "Train Precision: 1.00\n",
      "Validation Precision: 0.52\n",
      "Test Precision: 0.80\n",
      "=============Recall=============\n",
      "Train Recall: 1.00\n",
      "Validation Recall: 0.38\n",
      "Test Recall: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "def train_anomaly_detection_model(\n",
    "    train_df, val_df, test_df\n",
    ") -> tuple[lgb.Booster, pl.Series, pl.Series, pl.Series]:\n",
    "    # デフォルト設定を取得\n",
    "    config = get_default_config()\n",
    "\n",
    "    # 異常検知用に価格の境界を調整（外れ値を除去しない）_config,\n",
    "    config.price_lower_bound = 0\n",
    "    config.price_upper_bound = float(\"inf\")  # 無限大に設定\n",
    "    config.remove_outliers_val = False\n",
    "\n",
    "    # Preprocessorを作成\n",
    "    preprocessor = Preprocessor(**config.to_dict())\n",
    "    print(f\"Price bounds: {config.price_lower_bound} - {config.price_upper_bound}\")\n",
    "    print(f\"Remove outliers: {config.remove_outliers_val}\")\n",
    "\n",
    "    # preprocess the data again\n",
    "    train_df_preprocessed, val_df_preprocessed, test_df_preprocessed = preprocessor.run(\n",
    "        train_df, val_df, test_df\n",
    "    )\n",
    "\n",
    "    # anomaly anotation\n",
    "    anomaly_expr = (pl.col(\"price\") > 40_000).alias(\n",
    "        \"is_anomaly\"\n",
    "    )  # 価格が40,000を超える場合は外れ値とする\n",
    "\n",
    "    train_df_preprocessed = train_df_preprocessed.with_columns(anomaly_expr)\n",
    "    val_df_preprocessed = val_df_preprocessed.with_columns(anomaly_expr)\n",
    "    test_df_preprocessed = test_df_preprocessed.with_columns(anomaly_expr)\n",
    "\n",
    "    # モデルの学習\n",
    "    train_set = lgb.Dataset(\n",
    "        train_df_preprocessed.drop(\"is_anomaly\", \"price\").to_pandas(),\n",
    "        train_df_preprocessed[\"is_anomaly\"].to_pandas(),\n",
    "    )\n",
    "    val_set = lgb.Dataset(\n",
    "        val_df_preprocessed.drop(\"is_anomaly\", \"price\").to_pandas(),\n",
    "        val_df_preprocessed[\"is_anomaly\"].to_pandas(),\n",
    "        reference=train_set,\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_set],\n",
    "    )\n",
    "\n",
    "    # 予測\n",
    "    y_pred_train = model.predict(\n",
    "        train_df_preprocessed.drop(\"is_anomaly\", \"price\").to_pandas()\n",
    "    )\n",
    "    y_pred_val = model.predict(\n",
    "        val_df_preprocessed.drop(\"is_anomaly\", \"price\").to_pandas()\n",
    "    )\n",
    "    y_pred_test = model.predict(\n",
    "        test_df_preprocessed.drop(\"is_anomaly\", \"price\").to_pandas()\n",
    "    )\n",
    "\n",
    "    # 閾値\n",
    "    threshold = 0.2\n",
    "    print(f\"Threshold for anomaly detection: {threshold}\")\n",
    "\n",
    "    # precision\n",
    "    train_precision = precision_score(\n",
    "        train_df_preprocessed[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_train > threshold).astype(int),\n",
    "    )\n",
    "    val_precision = precision_score(\n",
    "        val_df_preprocessed[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_val > threshold).astype(int),\n",
    "    )\n",
    "    test_precision = precision_score(\n",
    "        test_df_preprocessed[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_test > threshold).astype(int),\n",
    "    )\n",
    "    print(\"=============Precision=============\")\n",
    "    print(f\"Train Precision: {train_precision:.2f}\")\n",
    "    print(f\"Validation Precision: {val_precision:.2f}\")\n",
    "    print(f\"Test Precision: {test_precision:.2f}\")\n",
    "\n",
    "    # recall\n",
    "    train_recall = recall_score(\n",
    "        train_df_preprocessed[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_train > threshold).astype(int),\n",
    "    )\n",
    "    val_recall = recall_score(\n",
    "        val_df_preprocessed[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_val > threshold).astype(int),\n",
    "    )\n",
    "    test_recall = recall_score(\n",
    "        test_df_preprocessed[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_test > threshold).astype(int),\n",
    "    )\n",
    "    print(\"=============Recall=============\")\n",
    "    print(f\"Train Recall: {train_recall:.2f}\")\n",
    "    print(f\"Validation Recall: {val_recall:.2f}\")\n",
    "    print(f\"Test Recall: {test_recall:.2f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "anomaly_detection_model = train_anomaly_detection_model(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8379590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data again\n",
    "train_df_preprocessed, val_df_preprocessed, test_df_preprocessed = preprocessor.run(\n",
    "    train_df, val_df, test_df\n",
    ")\n",
    "\n",
    "# anomaly anotation\n",
    "anomaly_expr = (pl.col(\"price\") > 40_000).alias(\n",
    "    \"is_anomaly\"\n",
    ")  # 価格が40,000を超える場合は外れ値とする\n",
    "\n",
    "train_df_preprocessed = train_df_preprocessed.with_columns(anomaly_expr)\n",
    "val_df_preprocessed = val_df_preprocessed.with_columns(anomaly_expr)\n",
    "test_df_preprocessed = test_df_preprocessed.with_columns(anomaly_expr)\n",
    "\n",
    "\n",
    "# モデルの学習\n",
    "train_set = lgb.Dataset(\n",
    "    train_df_preprocessed.drop(\"is_anomaly\", \"price\").to_pandas(),\n",
    "    train_df_preprocessed[\"is_anomaly\"].to_pandas(),\n",
    ")\n",
    "val_set = lgb.Dataset(\n",
    "    val_df_preprocessed.drop(\"is_anomaly\", \"price\").to_pandas(),\n",
    "    val_df_preprocessed[\"is_anomaly\"].to_pandas(),\n",
    "    reference=train_set,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_set,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[val_set],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef50e24",
   "metadata": {},
   "source": [
    "# Emsamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2927af50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant prediction for anomalies: 69,500\n"
     ]
    }
   ],
   "source": [
    "constant_prediction = train_df.filter(pl.col(\"price\") > 40_000)[\"price\"].quantile(0.9)\n",
    "print(f\"Constant prediction for anomalies: {constant_prediction:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5  # 定数の重み付け係数\n",
    "weight = y_pred_val**alpha\n",
    "\n",
    "ensemble_prediction_train = weight * y_pred_train + (1 - weight) * constant_prediction\n",
    "ensemble_prediction_val = weight * y_pred_val + (1 - weight) * constant_prediction\n",
    "\n",
    "# rmse\n",
    "train_rmse = rmse(\n",
    "    train_df_preprocessed[\"price\"].to_pandas(),\n",
    "    ensemble_prediction_train,\n",
    ")\n",
    "val_rmse = rmse(\n",
    "    val_df_preprocessed[\"price\"].to_pandas(),\n",
    "    ensemble_prediction_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7303647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load the datasets\n",
    "    train_df = pl.read_csv(\"../dataset/projectA_vehicle_train.csv\").drop(\n",
    "        \"posting_date\", \"id\"\n",
    "    )\n",
    "    val_df = pl.read_csv(\"../dataset/projectA_vehicle_val.csv\").drop(\n",
    "        \"posting_date\", \"id\"\n",
    "    )\n",
    "    test_df = pl.read_csv(\"../dataset/projectA_vehicle_test.csv\").drop(\n",
    "        \"posting_date\", \"id\"\n",
    "    )\n",
    "\n",
    "    # data for regression\n",
    "    train_df_reg, val_df_reg, test_df_reg = preprocess_for_regression(\n",
    "        train_df, val_df, test_df\n",
    "    )\n",
    "    price_pred_train, price_pred_val, price_pred_test = run_regression_model(\n",
    "        train_df_reg, val_df_reg, test_df_reg\n",
    "    )\n",
    "\n",
    "    # data for anomaly detection\n",
    "    train_df_anomaly, val_df_anomaly, test_df_anomaly = (\n",
    "        preprocess_for_anomaly_detection(train_df, val_df, test_df)\n",
    "    )\n",
    "    anomaly_pred_train, anomaly_pred_val, anomaly_pred_test = (\n",
    "        run_anomaly_detection_model(train_df_anomaly, val_df_anomaly, test_df_anomaly)\n",
    "    )\n",
    "\n",
    "    constant_prediction = 60_000\n",
    "    alpha = 0.5  # 定数の重み付け係数\n",
    "\n",
    "    ensembled_prediction_train = ensemble_predictions(\n",
    "        price_pred_train, anomaly_pred_train, constant_prediction, alpha\n",
    "    )\n",
    "    ensembled_prediction_val = ensemble_predictions(\n",
    "        price_pred_val, anomaly_pred_val, constant_prediction, alpha\n",
    "    )\n",
    "    ensembled_prediction_test = ensemble_predictions(\n",
    "        price_pred_test, anomaly_pred_test, constant_prediction, alpha\n",
    "    )\n",
    "\n",
    "    # rmse\n",
    "    train_rmse = rmse(\n",
    "        train_df_reg[\"price\"].to_numpy(),\n",
    "        ensembled_prediction_train,\n",
    "    )\n",
    "    val_rmse = rmse(\n",
    "        val_df_reg[\"price\"].to_numpy(),\n",
    "        ensembled_prediction_val,\n",
    "    )\n",
    "    test_rmse = rmse(\n",
    "        test_df_reg[\"price\"].to_numpy(),\n",
    "        ensembled_prediction_test,\n",
    "    )\n",
    "\n",
    "    print(f\"Ensembled Train RMSE: {train_rmse:,.0f}\")\n",
    "    print(f\"Ensembled Validation RMSE: {val_rmse:,.0f}\")\n",
    "    print(f\"Ensembled Test RMSE: {test_rmse:,.0f}\")\n",
    "\n",
    "\n",
    "def preprocess_for_regression(\n",
    "    train_df: pl.DataFrame,\n",
    "    val_df: pl.DataFrame,\n",
    "    test_df: pl.DataFrame,\n",
    ") -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "    config = get_default_config()\n",
    "\n",
    "    # 異常検知用に価格の境界を調整（外れ値を除去しない）_config,\n",
    "    config.price_lower_bound = 0\n",
    "    config.price_upper_bound = float(\"inf\")  # 無限大に設定\n",
    "    config.remove_outliers_val = False\n",
    "\n",
    "    # Preprocessorを作成\n",
    "    preprocessor = Preprocessor(**config.to_dict())\n",
    "\n",
    "    train_df_preprocessed, val_df_preprocessed, test_df_preprocessed = preprocessor.run(\n",
    "        train_df, val_df, test_df\n",
    "    )\n",
    "\n",
    "    return train_df_preprocessed, val_df_preprocessed, test_df_preprocessed\n",
    "\n",
    "\n",
    "def preprocess_for_anomaly_detection(\n",
    "    train_df: pl.DataFrame,\n",
    "    val_df: pl.DataFrame,\n",
    "    test_df: pl.DataFrame,\n",
    ") -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "    config = get_default_config()\n",
    "\n",
    "    # 異常検知用に価格の境界を調整（外れ値を除去しない）_config,\n",
    "    config.price_lower_bound = 0\n",
    "    config.price_upper_bound = float(\"inf\")  # 無限大に設定\n",
    "    config.remove_outliers_val = False\n",
    "\n",
    "    # Preprocessorを作成\n",
    "    preprocessor = Preprocessor(**config.to_dict())\n",
    "    print(f\"Price bounds: {config.price_lower_bound} - {config.price_upper_bound}\")\n",
    "    print(f\"Remove outliers: {config.remove_outliers_val}\")\n",
    "\n",
    "    # preprocess the data again\n",
    "    train_df_preprocessed, val_df_preprocessed, test_df_preprocessed = preprocessor.run(\n",
    "        train_df, val_df, test_df\n",
    "    )\n",
    "\n",
    "    # anomaly anotation\n",
    "    anomaly_expr = (pl.col(\"price\") > 40_000).alias(\n",
    "        \"is_anomaly\"\n",
    "    )  # 価格が40,000を超える場合は外れ値とする\n",
    "\n",
    "    train_df_preprocessed = train_df_preprocessed.with_columns(anomaly_expr).drop(\n",
    "        \"price\"\n",
    "    )\n",
    "    val_df_preprocessed = val_df_preprocessed.with_columns(anomaly_expr).drop(\"price\")\n",
    "    test_df_preprocessed = test_df_preprocessed.with_columns(anomaly_expr).drop(\"price\")\n",
    "\n",
    "    return train_df_preprocessed, val_df_preprocessed, test_df_preprocessed\n",
    "\n",
    "\n",
    "def remove_outliers(\n",
    "    df: pl.DataFrame,\n",
    "    lower_bound: float,\n",
    "    upper_bound: float,\n",
    ") -> pl.DataFrame:\n",
    "    return df.filter(\n",
    "        (pl.col(\"price\") >= lower_bound) & (pl.col(\"price\") <= upper_bound)\n",
    "    )\n",
    "\n",
    "\n",
    "def run_regression_model(\n",
    "    train_df: pl.DataFrame,\n",
    "    val_df: pl.DataFrame,\n",
    "    test_df: pl.DataFrame,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    train_df_filtered = remove_outliers(train_df, lower_bound=1_000, upper_bound=40_000)\n",
    "    val_df_filtered = remove_outliers(val_df, lower_bound=1_000, upper_bound=40_000)\n",
    "\n",
    "    # dataset\n",
    "    train_set = lgb.Dataset(\n",
    "        train_df_filtered.drop(\"price\").to_pandas(),\n",
    "        train_df_filtered[\"price\"].to_pandas(),\n",
    "    )\n",
    "    val_set = lgb.Dataset(\n",
    "        val_df_filtered.drop(\"price\").to_pandas(),\n",
    "        val_df_filtered[\"price\"].to_pandas(),\n",
    "        reference=train_set,\n",
    "    )\n",
    "\n",
    "    # モデルの学習\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    # モデルの学習\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_set],\n",
    "    )\n",
    "\n",
    "    # 予測\n",
    "    y_pred_train = model.predict(train_df.drop(\"price\").to_pandas())\n",
    "    y_pred_val = model.predict(val_df.drop(\"price\").to_pandas())\n",
    "    y_pred_test = model.predict(test_df.drop(\"price\").to_pandas())\n",
    "\n",
    "    # 評価\n",
    "    train_rmse = rmse(train_df[\"price\"].to_numpy(), y_pred_train)\n",
    "    val_rmse = rmse(val_df[\"price\"].to_numpy(), y_pred_val)\n",
    "    test_rmse = rmse(test_df[\"price\"].to_numpy(), y_pred_test)\n",
    "\n",
    "    print(f\"Train RMSE: {train_rmse:,.0f}\")\n",
    "    print(f\"Validation RMSE: {val_rmse:,.0f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:,.0f}\")\n",
    "\n",
    "    return y_pred_train, y_pred_val, y_pred_test\n",
    "\n",
    "\n",
    "def run_anomaly_detection_model(\n",
    "    train_df: pl.DataFrame,\n",
    "    val_df: pl.DataFrame,\n",
    "    test_df: pl.DataFrame,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    # モデルの学習\n",
    "    train_set = lgb.Dataset(\n",
    "        train_df.drop(\"is_anomaly\").to_pandas(),\n",
    "        train_df[\"is_anomaly\"].to_pandas(),\n",
    "    )\n",
    "    val_set = lgb.Dataset(\n",
    "        val_df.drop(\"is_anomaly\").to_pandas(),\n",
    "        val_df[\"is_anomaly\"].to_pandas(),\n",
    "        reference=train_set,\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_set],\n",
    "    )\n",
    "\n",
    "    # 予測\n",
    "    y_pred_train = model.predict(train_df.drop(\"is_anomaly\").to_pandas())\n",
    "    y_pred_val = model.predict(val_df.drop(\"is_anomaly\").to_pandas())\n",
    "    y_pred_test = model.predict(test_df.drop(\"is_anomaly\").to_pandas())\n",
    "\n",
    "    # 閾値\n",
    "    threshold = 0.2\n",
    "    print(f\"Threshold for anomaly detection: {threshold}\")\n",
    "\n",
    "    # precision\n",
    "    train_precision = precision_score(\n",
    "        train_df[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_train > threshold).astype(int),\n",
    "    )\n",
    "    val_precision = precision_score(\n",
    "        val_df[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_val > threshold).astype(int),\n",
    "    )\n",
    "    test_precision = precision_score(\n",
    "        test_df[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_test > threshold).astype(int),\n",
    "    )\n",
    "    print(\"=============Precision=============\")\n",
    "    print(f\"Train Precision: {train_precision:.2f}\")\n",
    "    print(f\"Validation Precision: {val_precision:.2f}\")\n",
    "    print(f\"Test Precision: {test_precision:.2f}\")\n",
    "\n",
    "    # recall\n",
    "    train_recall = recall_score(\n",
    "        train_df[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_train > threshold).astype(int),\n",
    "    )\n",
    "    val_recall = recall_score(\n",
    "        val_df[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_val > threshold).astype(int),\n",
    "    )\n",
    "    test_recall = recall_score(\n",
    "        test_df[\"is_anomaly\"].to_numpy(),\n",
    "        (y_pred_test > threshold).astype(int),\n",
    "    )\n",
    "    print(\"=============Recall=============\")\n",
    "    print(f\"Train Recall: {train_recall:.2f}\")\n",
    "    print(f\"Validation Recall: {val_recall:.2f}\")\n",
    "    print(f\"Test Recall: {test_recall:.2f}\")\n",
    "\n",
    "    return y_pred_train, y_pred_val, y_pred_test\n",
    "\n",
    "\n",
    "def ensemble_predictions(\n",
    "    price_predictions: np.ndarray,\n",
    "    anomaly_predictions: np.ndarray,\n",
    "    constant_prediction: float,\n",
    "    alpha: float = 0.9,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    アンサンブル予測を行う関数\n",
    "    :param price_predictions: 価格予測の配列\n",
    "    :param anomaly_predictions: 異常検知の予測値の配列\n",
    "    :param constant_prediction: 定数予測値\n",
    "    :param alpha: 異常検知の重み付け係数\n",
    "    0 <= alpha <= 1\n",
    "    :return: アンサンブル予測の配列\n",
    "    \"\"\"\n",
    "    weight = anomaly_predictions**alpha\n",
    "\n",
    "    ensemble_prediction = (\n",
    "        weight * price_predictions + (1 - weight) * constant_prediction\n",
    "    )\n",
    "\n",
    "    return ensemble_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a6ccef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 12,422,463\n",
      "Validation RMSE: 9,315\n",
      "Test RMSE: 7,589\n",
      "Price bounds: 0 - inf\n",
      "Remove outliers: False\n",
      "Threshold for anomaly detection: 0.2\n",
      "=============Precision=============\n",
      "Train Precision: 1.00\n",
      "Validation Precision: 0.52\n",
      "Test Precision: 0.79\n",
      "=============Recall=============\n",
      "Train Recall: 1.00\n",
      "Validation Recall: 0.38\n",
      "Test Recall: 0.53\n",
      "Ensembled Train RMSE: 12,422,545\n",
      "Ensembled Validation RMSE: 46,996\n",
      "Ensembled Test RMSE: 47,500\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896a903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
