{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7503609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import custom modules\n",
    "from src.metrics import rmse\n",
    "from src.features.preprocess import Preprocessor\n",
    "from src.config.preprocess import PreprocessorConfig\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a919c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 車両価格予測モデルの比較レポート\n",
    "\n",
    "## 概要\n",
    "\n",
    "本レポートでは、車両価格予測において、ベースライン手法と提案手法（Target Encoding + ハイパーパラメータ最適化）の性能を比較し、各手法の特徴と改善点について分析します。\n",
    "\n",
    "### 評価データセット\n",
    "- **訓練データ**: `projectA_vehicle_train.csv`\n",
    "- **検証データ**: `projectA_vehicle_val.csv`  \n",
    "- **テストデータ**: `projectA_vehicle_test.csv`\n",
    "\n",
    "### 評価指標\n",
    "- **RMSE (Root Mean Squared Error)**: 予測値と実際値の二乗平均平方根誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb4982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "dataset_path = Path(\"../dataset/\")\n",
    "\n",
    "# 不要な列を定義\n",
    "unnecessary_columns = [\"posting_date\", \"id\"]\n",
    "\n",
    "# Polars形式でデータ読み込み（提案手法用）\n",
    "train_df_pl = pl.read_csv(dataset_path / \"projectA_vehicle_train.csv\").drop(\n",
    "    unnecessary_columns\n",
    ")\n",
    "val_df_pl = pl.read_csv(dataset_path / \"projectA_vehicle_val.csv\").drop(\n",
    "    unnecessary_columns\n",
    ")\n",
    "test_df_pl = pl.read_csv(dataset_path / \"projectA_vehicle_test.csv\").drop(\n",
    "    unnecessary_columns\n",
    ")\n",
    "\n",
    "# Pandas形式でデータ読み込み（ベースライン手法用）\n",
    "usecols = [\n",
    "    \"price\",\n",
    "    \"year\",\n",
    "    \"manufacturer\",\n",
    "    \"condition\",\n",
    "    \"cylinders\",\n",
    "    \"fuel\",\n",
    "    \"odometer\",\n",
    "    \"transmission\",\n",
    "    \"drive\",\n",
    "    \"type\",\n",
    "    \"paint_color\",\n",
    "]\n",
    "\n",
    "train_df_pd = pd.read_csv(dataset_path / \"projectA_vehicle_train.csv\", usecols=usecols)\n",
    "val_df_pd = pd.read_csv(dataset_path / \"projectA_vehicle_val.csv\", usecols=usecols)\n",
    "test_df_pd = pd.read_csv(dataset_path / \"projectA_vehicle_test.csv\", usecols=usecols)\n",
    "\n",
    "print(\"データセットの形状:\")\n",
    "print(f\"訓練データ: {train_df_pd.shape}\")\n",
    "print(f\"検証データ: {val_df_pd.shape}\")\n",
    "print(f\"テストデータ: {test_df_pd.shape}\")\n",
    "\n",
    "# 基本統計量の表示\n",
    "print(\"\\n価格の基本統計量（訓練データ）:\")\n",
    "print(train_df_pd[\"price\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef3d38",
   "metadata": {},
   "source": [
    "## 1. ベースライン手法\n",
    "\n",
    "### 手法概要\n",
    "ベースライン手法では、以下の特徴を持つシンプルなアプローチを採用：\n",
    "\n",
    "1. **前処理**: 基本的な Label Encoding のみ\n",
    "2. **モデル**: LightGBM with デフォルトパラメータ\n",
    "3. **特徴量**: 基本的なカテゴリカル変数とそのまま数値変数を使用\n",
    "\n",
    "### 主な問題点\n",
    "- **単純な Label Encoding**: カテゴリの順序関係が価格予測に適さない可能性\n",
    "- **ハイパーパラメータ未調整**: デフォルト設定による最適化不足\n",
    "- **外れ値処理の不十分**: 極端な価格データの影響\n",
    "- **特徴量エンジニアリングの不足**: カテゴリ間の関係性を捉えきれない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベースライン手法の実装\n",
    "def train_baseline_model(train_df, val_df, test_df):\n",
    "    \"\"\"\n",
    "    ベースライン手法：Label Encoding + デフォルトLightGBM\n",
    "    \"\"\"\n",
    "    # データのコピー\n",
    "    train_processed = train_df.copy()\n",
    "    val_processed = val_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "    # カテゴリカル変数の特定\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    categorical_columns = []\n",
    "    for col in train_df.columns:\n",
    "        if col != \"price\" and train_df[col].dtype not in numerics:\n",
    "            categorical_columns.append(col)\n",
    "\n",
    "    print(\"カテゴリカル変数:\", categorical_columns)\n",
    "\n",
    "    # Label Encoding\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train_df[col].astype(str).values)\n",
    "        train_processed[col] = le.transform(train_df[col].astype(str).values)\n",
    "        val_processed[col] = le.transform(val_df[col].astype(str).values)\n",
    "        test_processed[col] = le.transform(test_df[col].astype(str).values)\n",
    "\n",
    "    # 外れ値フィルタリング（価格の上下限設定）\n",
    "    train_filtered = train_processed[\n",
    "        (train_processed[\"price\"] > 1000) & (train_processed[\"price\"] < 40000)\n",
    "    ]\n",
    "\n",
    "    # LightGBMデータセット作成\n",
    "    train_set = lgb.Dataset(\n",
    "        train_filtered.drop(columns=\"price\"), train_filtered[\"price\"]\n",
    "    )\n",
    "    val_set = lgb.Dataset(\n",
    "        val_processed.drop(columns=\"price\"), val_processed[\"price\"], reference=train_set\n",
    "    )\n",
    "\n",
    "    # ベースラインパラメータ（デフォルト設定）\n",
    "    baseline_params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"seed\": 42,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    # モデル訓練\n",
    "    model = lgb.train(\n",
    "        baseline_params,\n",
    "        train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_set],\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)],\n",
    "    )\n",
    "\n",
    "    return model, train_filtered, val_processed, test_processed\n",
    "\n",
    "\n",
    "# ベースライン手法の実行\n",
    "print(\"=== ベースライン手法の訓練 ===\")\n",
    "baseline_model, train_baseline, val_baseline, test_baseline = train_baseline_model(\n",
    "    train_df_pd, val_df_pd, test_df_pd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベースライン手法の評価\n",
    "def evaluate_model(model, train_df, val_df, test_df, method_name):\n",
    "    \"\"\"\n",
    "    モデルの評価を行い、RMSE スコアを計算\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # 訓練データでの評価\n",
    "    train_pred = model.predict(train_df.drop(columns=\"price\"))\n",
    "    train_rmse = rmse(train_df[\"price\"].values, train_pred)\n",
    "    results[\"train_rmse\"] = train_rmse\n",
    "\n",
    "    # 検証データでの評価\n",
    "    val_pred = model.predict(val_df.drop(columns=\"price\"))\n",
    "    val_rmse = rmse(val_df[\"price\"].values, val_pred)\n",
    "    results[\"val_rmse\"] = val_rmse\n",
    "\n",
    "    # テストデータでの評価\n",
    "    test_pred = model.predict(test_df.drop(columns=\"price\"))\n",
    "    test_rmse = rmse(test_df[\"price\"].values, test_pred)\n",
    "    results[\"test_rmse\"] = test_rmse\n",
    "\n",
    "    print(f\"=== {method_name} 評価結果 ===\")\n",
    "    print(f\"訓練データ RMSE: ${train_rmse:,.2f}\")\n",
    "    print(f\"検証データ RMSE: ${val_rmse:,.2f}\")\n",
    "    print(f\"テストデータ RMSE: ${test_rmse:,.2f}\")\n",
    "\n",
    "    return results, {\"train\": train_pred, \"val\": val_pred, \"test\": test_pred}\n",
    "\n",
    "\n",
    "# ベースライン手法の評価\n",
    "baseline_results, baseline_predictions = evaluate_model(\n",
    "    baseline_model, train_baseline, val_baseline, test_baseline, \"ベースライン手法\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bab768",
   "metadata": {},
   "source": [
    "## 2. 提案手法（Target Encoding + ハイパーパラメータ最適化）\n",
    "\n",
    "### 手法概要\n",
    "提案手法では、ベースライン手法の問題点を以下の方法で解決：\n",
    "\n",
    "1. **高度な特徴量エンジニアリング**: Target Encoding による統計的特徴量生成\n",
    "2. **過学習抑制**: Smoothing と Noise Level による正則化\n",
    "3. **ハイパーパラメータ最適化**: Optuna による自動最適化\n",
    "4. **複合エンコーディング**: Label Encoding + Target Encoding + Grouping の組み合わせ\n",
    "\n",
    "### Target Encoding の利点\n",
    "- **統計的意味**: カテゴリごとの目的変数（価格）の統計量を特徴量として活用\n",
    "- **過学習抑制**: Smoothing パラメータにより少数サンプルカテゴリの影響を調整\n",
    "- **ノイズ付加**: 訓練データへの過度な適合を防ぐためのランダムノイズ\n",
    "- **最小サンプル数**: 統計的信頼性を確保するための閾値設定\n",
    "\n",
    "### 最適化されたパラメータ\n",
    "以下のパラメータがOptuna により最適化されています："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7073f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化されたパラメータの読み込み\n",
    "params_path = Path(\"../params/\")\n",
    "\n",
    "# LightGBM パラメータの読み込み\n",
    "with open(params_path / \"best_lgb_params_reg.yaml\", \"r\") as f:\n",
    "    best_lgb_params = yaml.safe_load(f)\n",
    "\n",
    "# 前処理設定の読み込み\n",
    "best_preprocessor_config = PreprocessorConfig.from_yaml(\n",
    "    params_path / \"best_preprocessor_config_reg.yaml\"\n",
    ")\n",
    "\n",
    "print(\"=== 最適化されたLightGBMパラメータ ===\")\n",
    "for key, value in best_lgb_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n=== Target Encoding パラメータ ===\")\n",
    "target_config = best_preprocessor_config.condition_encoder_config.target_encoder_config\n",
    "print(f\"Smoothing: {target_config.smoothing:.6f}\")\n",
    "print(f\"Min Samples Leaf: {target_config.min_samples_leaf}\")\n",
    "print(f\"Noise Level: {target_config.noise_level:.6f}\")\n",
    "\n",
    "print(f\"\\n=== 価格フィルタリング設定 ===\")\n",
    "print(f\"価格下限: ${best_preprocessor_config.price_lower_bound:,.0f}\")\n",
    "print(f\"価格上限: ${best_preprocessor_config.price_upper_bound:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652cdfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提案手法の実装\n",
    "def train_proposed_model(train_df, val_df, test_df, preprocessor_config, lgb_params):\n",
    "    \"\"\"\n",
    "    提案手法：Target Encoding + 最適化ハイパーパラメータ\n",
    "    \"\"\"\n",
    "    print(\"=== 提案手法：前処理の実行 ===\")\n",
    "    # 前処理の実行\n",
    "    preprocessor = Preprocessor(**preprocessor_config.to_dict())\n",
    "    train_processed, val_processed, test_processed = preprocessor.run(\n",
    "        train_df, val_df, test_df\n",
    "    )\n",
    "\n",
    "    print(f\"前処理後の特徴量数: {train_processed.select(pl.exclude('price')).shape[1]}\")\n",
    "\n",
    "    # LightGBMデータセット作成\n",
    "    train_set = lgb.Dataset(\n",
    "        train_processed.drop(\"price\").to_pandas(), train_processed[\"price\"].to_pandas()\n",
    "    )\n",
    "    val_set = lgb.Dataset(\n",
    "        val_processed.drop(\"price\").to_pandas(),\n",
    "        val_processed[\"price\"].to_pandas(),\n",
    "        reference=train_set,\n",
    "    )\n",
    "\n",
    "    print(\"=== 提案手法：モデル訓練 ===\")\n",
    "    # モデル訓練\n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_set,\n",
    "        num_boost_round=best_lgb_params[\"n_estimators\"],\n",
    "        valid_sets=[val_set],\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)],\n",
    "    )\n",
    "\n",
    "    return model, train_processed, val_processed, test_processed\n",
    "\n",
    "\n",
    "# 提案手法の実行\n",
    "proposed_model, train_proposed, val_proposed, test_proposed = train_proposed_model(\n",
    "    train_df_pl, val_df_pl, test_df_pl, best_preprocessor_config, best_lgb_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提案手法の評価（Polars対応版）\n",
    "def evaluate_model_polars(model, train_df, val_df, test_df, method_name):\n",
    "    \"\"\"\n",
    "    Polarsデータフレーム用のモデル評価関数\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # 訓練データでの評価\n",
    "    train_pred = model.predict(train_df.drop(\"price\").to_pandas())\n",
    "    train_rmse = rmse(train_df[\"price\"].to_numpy(), train_pred)\n",
    "    results[\"train_rmse\"] = train_rmse\n",
    "\n",
    "    # 検証データでの評価\n",
    "    val_pred = model.predict(val_df.drop(\"price\").to_pandas())\n",
    "    val_rmse = rmse(val_df[\"price\"].to_numpy(), val_pred)\n",
    "    results[\"val_rmse\"] = val_rmse\n",
    "\n",
    "    # テストデータでの評価\n",
    "    test_pred = model.predict(test_df.drop(\"price\").to_pandas())\n",
    "    test_rmse = rmse(test_df[\"price\"].to_numpy(), test_pred)\n",
    "    results[\"test_rmse\"] = test_rmse\n",
    "\n",
    "    print(f\"=== {method_name} 評価結果 ===\")\n",
    "    print(f\"訓練データ RMSE: ${train_rmse:,.2f}\")\n",
    "    print(f\"検証データ RMSE: ${val_rmse:,.2f}\")\n",
    "    print(f\"テストデータ RMSE: ${test_rmse:,.2f}\")\n",
    "\n",
    "    return results, {\"train\": train_pred, \"val\": val_pred, \"test\": test_pred}\n",
    "\n",
    "\n",
    "# 提案手法の評価\n",
    "proposed_results, proposed_predictions = evaluate_model_polars(\n",
    "    proposed_model, train_proposed, val_proposed, test_proposed, \"提案手法\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcad18c",
   "metadata": {},
   "source": [
    "## 3. 手法比較と結果分析\n",
    "\n",
    "### 3.1 RMSE スコア比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ce1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果比較の可視化\n",
    "def create_comparison_plots():\n",
    "    \"\"\"\n",
    "    ベースライン手法と提案手法の比較プロット作成\n",
    "    \"\"\"\n",
    "    # 結果をまとめる\n",
    "    comparison_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Dataset\": [\"Train\", \"Validation\", \"Test\"],\n",
    "            \"Baseline\": [\n",
    "                baseline_results[\"train_rmse\"],\n",
    "                baseline_results[\"val_rmse\"],\n",
    "                baseline_results[\"test_rmse\"],\n",
    "            ],\n",
    "            \"Proposed\": [\n",
    "                proposed_results[\"train_rmse\"],\n",
    "                proposed_results[\"val_rmse\"],\n",
    "                proposed_results[\"test_rmse\"],\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 改善率の計算\n",
    "    comparison_df[\"Improvement (%)\"] = (\n",
    "        (comparison_df[\"Baseline\"] - comparison_df[\"Proposed\"])\n",
    "        / comparison_df[\"Baseline\"]\n",
    "        * 100\n",
    "    )\n",
    "\n",
    "    # プロットの作成\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # RMSE比較\n",
    "    x = np.arange(len(comparison_df))\n",
    "    width = 0.35\n",
    "\n",
    "    axes[0].bar(\n",
    "        x - width / 2,\n",
    "        comparison_df[\"Baseline\"],\n",
    "        width,\n",
    "        label=\"Baseline\",\n",
    "        alpha=0.8,\n",
    "        color=\"lightcoral\",\n",
    "    )\n",
    "    axes[0].bar(\n",
    "        x + width / 2,\n",
    "        comparison_df[\"Proposed\"],\n",
    "        width,\n",
    "        label=\"Proposed\",\n",
    "        alpha=0.8,\n",
    "        color=\"skyblue\",\n",
    "    )\n",
    "\n",
    "    axes[0].set_xlabel(\"Dataset\")\n",
    "    axes[0].set_ylabel(\"RMSE ($)\")\n",
    "    axes[0].set_title(\"RMSE Comparison: Baseline vs Proposed Method\")\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(comparison_df[\"Dataset\"])\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # 値をバーの上に表示\n",
    "    for i, (baseline, proposed) in enumerate(\n",
    "        zip(comparison_df[\"Baseline\"], comparison_df[\"Proposed\"])\n",
    "    ):\n",
    "        axes[0].text(\n",
    "            i - width / 2,\n",
    "            baseline + 200,\n",
    "            f\"${baseline:,.0f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "        axes[0].text(\n",
    "            i + width / 2,\n",
    "            proposed + 200,\n",
    "            f\"${proposed:,.0f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    # 改善率のプロット\n",
    "    colors = [\"green\" if x > 0 else \"red\" for x in comparison_df[\"Improvement (%)\"]]\n",
    "    bars = axes[1].bar(\n",
    "        comparison_df[\"Dataset\"],\n",
    "        comparison_df[\"Improvement (%)\"],\n",
    "        color=colors,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    axes[1].set_xlabel(\"Dataset\")\n",
    "    axes[1].set_ylabel(\"Improvement (%)\")\n",
    "    axes[1].set_title(\"Performance Improvement (%)\")\n",
    "    axes[1].grid(axis=\"y\", alpha=0.3)\n",
    "    axes[1].axhline(y=0, color=\"black\", linestyle=\"-\", alpha=0.3)\n",
    "\n",
    "    # 改善率の値を表示\n",
    "    for bar, improvement in zip(bars, comparison_df[\"Improvement (%)\"]):\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + (0.5 if height > 0 else -1),\n",
    "            f\"{improvement:.1f}%\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\" if height > 0 else \"top\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "\n",
    "# 比較表とプロットの作成\n",
    "print(\"=== 手法比較結果 ===\")\n",
    "comparison_results = create_comparison_plots()\n",
    "print(\"\\n詳細比較表:\")\n",
    "print(comparison_results.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f32413",
   "metadata": {},
   "source": [
    "### 3.2 特徴量重要度分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7130b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量重要度の比較\n",
    "def compare_feature_importance():\n",
    "    \"\"\"\n",
    "    ベースライン手法と提案手法の特徴量重要度を比較\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    # ベースライン手法の特徴量重要度\n",
    "    baseline_importance = baseline_model.feature_importance(importance_type=\"gain\")\n",
    "    baseline_features = train_baseline.drop(columns=\"price\").columns.tolist()\n",
    "\n",
    "    baseline_df = (\n",
    "        pd.DataFrame({\"feature\": baseline_features, \"importance\": baseline_importance})\n",
    "        .sort_values(\"importance\", ascending=True)\n",
    "        .tail(10)\n",
    "    )\n",
    "\n",
    "    axes[0].barh(\n",
    "        baseline_df[\"feature\"], baseline_df[\"importance\"], color=\"lightcoral\", alpha=0.8\n",
    "    )\n",
    "    axes[0].set_title(\"Baseline Method: Top 10 Feature Importance\", fontsize=14)\n",
    "    axes[0].set_xlabel(\"Importance (Gain)\")\n",
    "    axes[0].grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "    # 提案手法の特徴量重要度\n",
    "    proposed_importance = proposed_model.feature_importance(importance_type=\"gain\")\n",
    "    proposed_features = train_proposed.drop(\"price\").columns\n",
    "\n",
    "    proposed_df = (\n",
    "        pd.DataFrame({\"feature\": proposed_features, \"importance\": proposed_importance})\n",
    "        .sort_values(\"importance\", ascending=True)\n",
    "        .tail(15)\n",
    "    )\n",
    "\n",
    "    axes[1].barh(\n",
    "        proposed_df[\"feature\"], proposed_df[\"importance\"], color=\"skyblue\", alpha=0.8\n",
    "    )\n",
    "    axes[1].set_title(\"Proposed Method: Top 15 Feature Importance\", fontsize=14)\n",
    "    axes[1].set_xlabel(\"Importance (Gain)\")\n",
    "    axes[1].grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"=== ベースライン手法 トップ10 特徴量 ===\")\n",
    "    for idx, row in baseline_df.iterrows():\n",
    "        print(f\"{row['feature']}: {row['importance']:.0f}\")\n",
    "\n",
    "    print(\"\\n=== 提案手法 トップ15 特徴量 ===\")\n",
    "    for idx, row in proposed_df.iterrows():\n",
    "        print(f\"{row['feature']}: {row['importance']:.0f}\")\n",
    "\n",
    "    return baseline_df, proposed_df\n",
    "\n",
    "\n",
    "baseline_importance_df, proposed_importance_df = compare_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb4759",
   "metadata": {},
   "source": [
    "### 3.3 予測精度の詳細分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測精度の詳細分析\n",
    "def analyze_prediction_quality():\n",
    "    \"\"\"\n",
    "    両手法の予測精度を詳細分析\n",
    "    \"\"\"\n",
    "    # 検証データでの分析\n",
    "    val_actual = val_baseline[\"price\"].values\n",
    "    baseline_pred = baseline_predictions[\"val\"]\n",
    "    proposed_pred = proposed_predictions[\"val\"]\n",
    "\n",
    "    # 残差の計算\n",
    "    baseline_residuals = val_actual - baseline_pred\n",
    "    proposed_residuals = val_proposed[\"price\"].to_numpy() - proposed_pred\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # 実際値 vs 予測値の散布図\n",
    "    axes[0, 0].scatter(\n",
    "        val_actual, baseline_pred, alpha=0.5, s=20, color=\"lightcoral\", label=\"Baseline\"\n",
    "    )\n",
    "    axes[0, 0].scatter(\n",
    "        val_proposed[\"price\"].to_numpy(),\n",
    "        proposed_pred,\n",
    "        alpha=0.5,\n",
    "        s=20,\n",
    "        color=\"skyblue\",\n",
    "        label=\"Proposed\",\n",
    "    )\n",
    "    max_price = max(val_actual.max(), baseline_pred.max(), proposed_pred.max())\n",
    "    axes[0, 0].plot(\n",
    "        [0, max_price], [0, max_price], \"r--\", alpha=0.8, label=\"Perfect Prediction\"\n",
    "    )\n",
    "    axes[0, 0].set_xlabel(\"Actual Price ($)\")\n",
    "    axes[0, 0].set_ylabel(\"Predicted Price ($)\")\n",
    "    axes[0, 0].set_title(\"Actual vs Predicted Price (Validation Set)\")\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # 残差の分布比較\n",
    "    axes[0, 1].hist(\n",
    "        baseline_residuals,\n",
    "        bins=50,\n",
    "        alpha=0.7,\n",
    "        color=\"lightcoral\",\n",
    "        label=f\"Baseline (std={np.std(baseline_residuals):.0f})\",\n",
    "        density=True,\n",
    "    )\n",
    "    axes[0, 1].hist(\n",
    "        proposed_residuals,\n",
    "        bins=50,\n",
    "        alpha=0.7,\n",
    "        color=\"skyblue\",\n",
    "        label=f\"Proposed (std={np.std(proposed_residuals):.0f})\",\n",
    "        density=True,\n",
    "    )\n",
    "    axes[0, 1].axvline(x=0, color=\"red\", linestyle=\"--\", alpha=0.8)\n",
    "    axes[0, 1].set_xlabel(\"Residuals (Actual - Predicted)\")\n",
    "    axes[0, 1].set_ylabel(\"Density\")\n",
    "    axes[0, 1].set_title(\"Distribution of Residuals\")\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # 価格帯別の誤差分析\n",
    "    price_bins = pd.cut(\n",
    "        val_actual, bins=5, labels=[\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"]\n",
    "    )\n",
    "    baseline_errors_by_price = (\n",
    "        pd.DataFrame({\"price_bin\": price_bins, \"abs_error\": np.abs(baseline_residuals)})\n",
    "        .groupby(\"price_bin\")[\"abs_error\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    proposed_errors_by_price = (\n",
    "        pd.DataFrame({\"price_bin\": price_bins, \"abs_error\": np.abs(proposed_residuals)})\n",
    "        .groupby(\"price_bin\")[\"abs_error\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    x = np.arange(len(baseline_errors_by_price))\n",
    "    width = 0.35\n",
    "    axes[1, 0].bar(\n",
    "        x - width / 2,\n",
    "        baseline_errors_by_price.values,\n",
    "        width,\n",
    "        label=\"Baseline\",\n",
    "        color=\"lightcoral\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    axes[1, 0].bar(\n",
    "        x + width / 2,\n",
    "        proposed_errors_by_price.values,\n",
    "        width,\n",
    "        label=\"Proposed\",\n",
    "        color=\"skyblue\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    axes[1, 0].set_xlabel(\"Price Range\")\n",
    "    axes[1, 0].set_ylabel(\"Mean Absolute Error ($)\")\n",
    "    axes[1, 0].set_title(\"Mean Absolute Error by Price Range\")\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels(baseline_errors_by_price.index, rotation=45)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # 相対誤差の比較\n",
    "    baseline_rel_error = np.abs(baseline_residuals) / val_actual\n",
    "    proposed_rel_error = np.abs(proposed_residuals) / val_proposed[\"price\"].to_numpy()\n",
    "\n",
    "    axes[1, 1].boxplot(\n",
    "        [baseline_rel_error, proposed_rel_error], labels=[\"Baseline\", \"Proposed\"]\n",
    "    )\n",
    "    axes[1, 1].set_ylabel(\"Relative Error (|residual| / actual_price)\")\n",
    "    axes[1, 1].set_title(\"Relative Error Distribution\")\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 統計サマリーの表示\n",
    "    print(\"=== 予測精度統計サマリー（検証データ） ===\")\n",
    "    print(f\"ベースライン手法:\")\n",
    "    print(f\"  - MAE: ${np.mean(np.abs(baseline_residuals)):,.2f}\")\n",
    "    print(\n",
    "        f\"  - MAPE: {np.mean(baseline_rel_error):.3f} ({np.mean(baseline_rel_error) * 100:.1f}%)\"\n",
    "    )\n",
    "    print(f\"  - 残差標準偏差: ${np.std(baseline_residuals):,.2f}\")\n",
    "\n",
    "    print(f\"\\n提案手法:\")\n",
    "    print(f\"  - MAE: ${np.mean(np.abs(proposed_residuals)):,.2f}\")\n",
    "    print(\n",
    "        f\"  - MAPE: {np.mean(proposed_rel_error):.3f} ({np.mean(proposed_rel_error) * 100:.1f}%)\"\n",
    "    )\n",
    "    print(f\"  - 残差標準偏差: ${np.std(proposed_residuals):,.2f}\")\n",
    "\n",
    "\n",
    "analyze_prediction_quality()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cc53a",
   "metadata": {},
   "source": [
    "## 4. 結論と考察\n",
    "\n",
    "### 4.1 主要な改善点\n",
    "\n",
    "提案手法（Target Encoding + ハイパーパラメータ最適化）により、以下の改善が確認されました：\n",
    "\n",
    "1. **予測精度の向上**: 検証データでのRMSE改善\n",
    "2. **特徴量の有効活用**: Target Encodingにより統計的に意味のある特徴量を生成\n",
    "3. **過学習の抑制**: Smoothing、Noise Level、min_samples_leafによる正則化効果\n",
    "4. **ハイパーパラメータ最適化**: Optunaによる体系的な最適化\n",
    "\n",
    "### 4.2 Target Encodingの効果\n",
    "\n",
    "Target Encodingにより以下の利点が得られました：\n",
    "- **統計的特徴量**: カテゴリごとの目的変数統計量を直接利用\n",
    "- **高次元カテゴリ対応**: 多数のカテゴリを持つ変数（manufacturer, stateなど）の効果的処理\n",
    "- **過学習防止**: 適切な正則化パラメータによる汎化性能向上\n",
    "\n",
    "### 4.3 今後の改善可能性\n",
    "\n",
    "さらなる性能向上のための方向性：\n",
    "1. **外部データ統合**: 経済指標、地域情報など\n",
    "2. **アンサンブル手法**: 複数モデルの組み合わせ\n",
    "3. **深層学習**: ニューラルネットワークベースの手法\n",
    "4. **特徴量選択**: より精密な特徴量選択手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終サマリー表の作成\n",
    "def create_final_summary():\n",
    "    \"\"\"\n",
    "    両手法の最終的な比較サマリーを作成\n",
    "    \"\"\"\n",
    "    summary_data = {\n",
    "        \"項目\": [\n",
    "            \"RMSE (訓練)\",\n",
    "            \"RMSE (検証)\",\n",
    "            \"RMSE (テスト)\",\n",
    "            \"特徴量数\",\n",
    "            \"前処理手法\",\n",
    "            \"ハイパーパラメータ\",\n",
    "            \"過学習対策\",\n",
    "        ],\n",
    "        \"ベースライン手法\": [\n",
    "            f\"${baseline_results['train_rmse']:,.0f}\",\n",
    "            f\"${baseline_results['val_rmse']:,.0f}\",\n",
    "            f\"${baseline_results['test_rmse']:,.0f}\",\n",
    "            f\"{len(train_baseline.columns) - 1}個\",\n",
    "            \"Label Encoding\",\n",
    "            \"デフォルト設定\",\n",
    "            \"簡易的フィルタリング\",\n",
    "        ],\n",
    "        \"提案手法\": [\n",
    "            f\"${proposed_results['train_rmse']:,.0f}\",\n",
    "            f\"${proposed_results['val_rmse']:,.0f}\",\n",
    "            f\"${proposed_results['test_rmse']:,.0f}\",\n",
    "            f\"{len(train_proposed.columns) - 1}個\",\n",
    "            \"Target Encoding + Label Encoding\",\n",
    "            \"Optuna最適化\",\n",
    "            \"Smoothing + Noise + 統計的閾値\",\n",
    "        ],\n",
    "        \"改善率\": [\n",
    "            f\"{((baseline_results['train_rmse'] - proposed_results['train_rmse']) / baseline_results['train_rmse'] * 100):+.1f}%\",\n",
    "            f\"{((baseline_results['val_rmse'] - proposed_results['val_rmse']) / baseline_results['val_rmse'] * 100):+.1f}%\",\n",
    "            f\"{((baseline_results['test_rmse'] - proposed_results['test_rmse']) / baseline_results['test_rmse'] * 100):+.1f}%\",\n",
    "            f\"+{len(train_proposed.columns) - len(train_baseline.columns)}個\",\n",
    "            \"統計的手法採用\",\n",
    "            \"自動最適化\",\n",
    "            \"多層的正則化\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"=== 最終比較サマリー ===\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "final_summary = create_final_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"レポート作成完了!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
